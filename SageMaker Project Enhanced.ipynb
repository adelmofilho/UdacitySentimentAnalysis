{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "data_folder = \"aclImdb\"\n",
    "data_url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filename = \"aclImdb_v1.tar.gz\"\n",
    "sample_idx = 42\n",
    "cache_dir = os.path.join(\"cache\", \"sentiment_analysis\")\n",
    "pytorch_dir = 'data/pytorch' # The folder we will use for storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "def download_data(data_dir, data_url, filename):\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    download = urlretrieve(url=data_url, filename=Path(data_dir).joinpath(filename))\n",
    "    tar = tarfile.open(name=download[0], mode='r|*')\n",
    "    tar.extractall(data_dir)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(data_dir, data_url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def read_imdb_data(data_dir, data_folder):\n",
    "    imdb_dir = Path(data_dir).joinpath(data_folder)\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for data_type in ['train', 'test']:\n",
    "        data[data_type] = {}\n",
    "        labels[data_type] = {}\n",
    "        \n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            data[data_type][sentiment] = []\n",
    "            labels[data_type][sentiment] = []\n",
    "            \n",
    "            path = os.path.join(imdb_dir, data_type, sentiment, '*.txt')\n",
    "            files = glob.glob(path)\n",
    "            \n",
    "            for f in files:\n",
    "                with open(f) as review:\n",
    "                    data[data_type][sentiment].append(review.read())\n",
    "                    # Here we represent a positive review by '1' and a negative review by '0'\n",
    "                    labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
    "                    \n",
    "            assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
    "                \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = read_imdb_data(data_dir, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
    "            len(data['train']['pos']), len(data['train']['neg']),\n",
    "            len(data['test']['pos']), len(data['test']['neg'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def prepare_imdb_data(data, labels):\n",
    "    \"\"\"Prepare training and test sets from IMDb movie reviews.\"\"\"\n",
    "    \n",
    "    #Combine positive and negative reviews and labels\n",
    "    data_train = data['train']['pos'] + data['train']['neg']\n",
    "    data_test = data['test']['pos'] + data['test']['neg']\n",
    "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
    "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
    "    \n",
    "    #Shuffle reviews and corresponding labels within training and test sets\n",
    "    data_train, labels_train = shuffle(data_train, labels_train)\n",
    "    data_test, labels_test = shuffle(data_test, labels_test)\n",
    "    \n",
    "    # Return a unified training data, test data, training labels, test labets\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_X, test_X, train_valid_y, test_y = prepare_imdb_data(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_validation_data(train_valid_X, train_valid_y, valid_size=0.3, random_state=42):\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_valid_X,\n",
    "                                                          train_valid_y, \n",
    "                                                          test_size=valid_size, \n",
    "                                                          random_state=random_state)\n",
    "    return train_X, valid_X, train_y, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_y, valid_y = split_train_validation_data(train_valid_X, train_valid_y, valid_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb reviews (combined): train = 17500, valid = 7500, test = 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"IMDb reviews (combined): train = {}, valid = {}, test = {}\".format(len(train_X), len(valid_X),len(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 0\n",
      "review: I couldn't believe how lame & pointless this was. Basically there is nothing to laugh at in the movie, hardly any scenes to get you interested in the rest of the movie. This movie pulled in some huge stars but they were all wasted in my opinion. I think Keanu Reeves must've taken some acting lessons a fews years after this movie before he stared in The Matrix. Uma Thurman looked very simple & humble. Luckily i got this movie for a very low price because its certainly not a movie to remember for any good reasons. I won't write anything about the story of the movie, but as you should know that she is meant to be the most famous hitchhiker across America because of her huge thumb. I would give this movie a 2 / 10. Before I watched this movie I was wondering why this movie has only got a 4.0/10, & now I know why. A very disappointing movie. Don't buy it even if you see it for under $5.\n"
     ]
    }
   ],
   "source": [
    "print(f\"sentiment: {train_y[sample_idx]}\")\n",
    "print(f\"review: {train_X[sample_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 1\n",
      "review: **** Includes Spoilers ****<br /><br />I've been a horror film fan now for many decades. Just when I think I've seen all the great ones another pops up to surprise me. I had never seen this film before. It was a treat, off the beaten path too...not just the path to the swamp ferry boat either. Here was a horror film made in the 1940s that dared to try something VERY different. The pretty girl is (gulp) fearless for a change and saves the men, including the man she loves, from the monster ! How is that for a twist. This girl was the complete opposite of most women in films of that time, no screaming at her own shadow, no fainting from fright, no tripping over a leaf as she runs. This gal wasn't afraid to live alone in a secluded hut far away from the rest of the villagers. Not only that but the place was on a foggy swamp rumored to be haunted. Heck she even takes naps on the swamp grass outdoors...like a regular 1940s version of Ripley. No snake, gator or ghostly strangler would dare bother this gal. Books on early feminist films should be sure to include this overlooked work.<br /><br />See this if you are a fan, like me, of those wonderfully atmospheric classic B/W horror films they made only in the 30s and 40s. And be sure to wear your cast iron turtle neck for protection.\n"
     ]
    }
   ],
   "source": [
    "print(f\"sentiment: {valid_y[sample_idx]}\")\n",
    "print(f\"review: {valid_X[sample_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: 1\n",
      "review: Why do I give this 1974 porn movie 7 points? Because I watched it. And I found it hilarious! Aliens, their weird spaceship, their weird helmets... my God, was that a sight. And all what these desperate alien women need is semen from the earth.<br /><br />And where do they look for it? In upper Bavaria, Germany. And that is where the main fun comes from: In Europe (and more so in German-speaking countries), Bavaria is seen as a traditional and backward region. And then the actors are so helpless with the alien women. Well, there have been films about people being unable to deal with women like the \"American Pie\" series.<br /><br />But what this film achieved is a true, funny weirdness. You constantly wonder how they came up with these crackpot ideas. But it was 1974, and looking back 35 years fills one with a kind of nostalgia. You've never seen a film like that.<br /><br />And if you don't mind seeing the casual pubic hairs and breasts, watch it once. It is a comedy essentially, not a porn flick.\n"
     ]
    }
   ],
   "source": [
    "print(f\"sentiment: {test_y[sample_idx]}\")\n",
    "print(f\"review: {test_X[sample_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_words(review):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['believ', 'lame', 'pointless', 'basic', 'noth', 'laugh', 'movi', 'hardli', 'scene', 'get', 'interest', 'rest', 'movi', 'movi', 'pull', 'huge', 'star', 'wast', 'opinion', 'think', 'keanu', 'reev', 'must', 'taken', 'act', 'lesson', 'few', 'year', 'movi', 'stare', 'matrix', 'uma', 'thurman', 'look', 'simpl', 'humbl', 'luckili', 'got', 'movi', 'low', 'price', 'certainli', 'movi', 'rememb', 'good', 'reason', 'write', 'anyth', 'stori', 'movi', 'know', 'meant', 'famou', 'hitchhik', 'across', 'america', 'huge', 'thumb', 'would', 'give', 'movi', '2', '10', 'watch', 'movi', 'wonder', 'movi', 'got', '4', '0', '10', 'know', 'disappoint', 'movi', 'buy', 'even', 'see', '5']\n"
     ]
    }
   ],
   "source": [
    "print(review_to_words(train_X[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['includ', 'spoiler', 'horror', 'film', 'fan', 'mani', 'decad', 'think', 'seen', 'great', 'one', 'anoth', 'pop', 'surpris', 'never', 'seen', 'film', 'treat', 'beaten', 'path', 'path', 'swamp', 'ferri', 'boat', 'either', 'horror', 'film', 'made', '1940', 'dare', 'tri', 'someth', 'differ', 'pretti', 'girl', 'gulp', 'fearless', 'chang', 'save', 'men', 'includ', 'man', 'love', 'monster', 'twist', 'girl', 'complet', 'opposit', 'women', 'film', 'time', 'scream', 'shadow', 'faint', 'fright', 'trip', 'leaf', 'run', 'gal', 'afraid', 'live', 'alon', 'seclud', 'hut', 'far', 'away', 'rest', 'villag', 'place', 'foggi', 'swamp', 'rumor', 'haunt', 'heck', 'even', 'take', 'nap', 'swamp', 'grass', 'outdoor', 'like', 'regular', '1940', 'version', 'ripley', 'snake', 'gator', 'ghostli', 'strangler', 'would', 'dare', 'bother', 'gal', 'book', 'earli', 'feminist', 'film', 'sure', 'includ', 'overlook', 'work', 'see', 'fan', 'like', 'wonder', 'atmospher', 'classic', 'b', 'w', 'horror', 'film', 'made', '30', '40', 'sure', 'wear', 'cast', 'iron', 'turtl', 'neck', 'protect']\n"
     ]
    }
   ],
   "source": [
    "print(review_to_words(valid_X[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['give', '1974', 'porn', 'movi', '7', 'point', 'watch', 'found', 'hilari', 'alien', 'weird', 'spaceship', 'weird', 'helmet', 'god', 'sight', 'desper', 'alien', 'women', 'need', 'semen', 'earth', 'look', 'upper', 'bavaria', 'germani', 'main', 'fun', 'come', 'europ', 'german', 'speak', 'countri', 'bavaria', 'seen', 'tradit', 'backward', 'region', 'actor', 'helpless', 'alien', 'women', 'well', 'film', 'peopl', 'unabl', 'deal', 'women', 'like', 'american', 'pie', 'seri', 'film', 'achiev', 'true', 'funni', 'weird', 'constantli', 'wonder', 'came', 'crackpot', 'idea', '1974', 'look', 'back', '35', 'year', 'fill', 'one', 'kind', 'nostalgia', 'never', 'seen', 'film', 'like', 'mind', 'see', 'casual', 'pubic', 'hair', 'breast', 'watch', 'comedi', 'essenti', 'porn', 'flick']\n"
     ]
    }
   ],
   "source": [
    "print(review_to_words(test_X[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "def preprocess_data(data_train, data_test, data_valid, \n",
    "                    labels_train, labels_test, labels_valid,\n",
    "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "    # If cache is missing, then do the heavy lifting\n",
    "    if cache_data is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        #words_train = list(map(review_to_words, data_train))\n",
    "        #words_test = list(map(review_to_words, data_test))\n",
    "        words_train = [review_to_words(review) for review in tqdm(data_train)]\n",
    "        words_valid = [review_to_words(review) for review in tqdm(data_valid)]\n",
    "        words_test = [review_to_words(review) for review in tqdm(data_test)]\n",
    "        # Write to cache file for future runs\n",
    "        if cache_file is not None:\n",
    "            cache_data = dict(words_train=words_train, words_test=words_test,words_valid=words_valid,\n",
    "                              labels_train=labels_train, labels_test=labels_test, labels_valid=labels_valid)\n",
    "            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
    "                pickle.dump(cache_data, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        words_train, words_test, words_valid, labels_train, labels_test, labels_valid = (cache_data['words_train'],\n",
    "                cache_data['words_test'], cache_data['words_valid'], \n",
    "                cache_data['labels_train'], cache_data['labels_test'], cache_data['labels_valid'])\n",
    "    return words_train, words_test, words_valid, labels_train, labels_test, labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read preprocessed data from cache file: preprocessed_data.pkl\n"
     ]
    }
   ],
   "source": [
    "train_pp_X, test_pp_X, valid_pp_X, train_pp_y, test_pp_y, valid_pp_y = preprocess_data(train_X, test_X, valid_X,\n",
    "                                                                           train_y, test_y, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "\n",
    "    flatten_data = [word for review in data for word in review]\n",
    "    (unique, counts) = np.unique(flatten_data, return_counts=True)   \n",
    "\n",
    "    # word_count = {}\n",
    "    # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    word_count = zip_word_count = {x:y for x,y in zip(unique, counts)}\n",
    "    \n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    #sorted_zip_word_count = [{key: value} for (key, value) in sorted(zip_word_count.items(), key=lambda x: x[1], reverse=True)]\n",
    "    #sorted_words = dict((key, val) for k in sorted_zip_word_count for key, val in k.items())\n",
    "    sorted_words = list(key for (key, value) in sorted(zip_word_count.items(), key=lambda x: x[1], reverse=True))\n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "         word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict, sorted_words, word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict, sorted_words, word_count = build_dict(train_pp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26222</th>\n",
       "      <td>movi</td>\n",
       "      <td>36240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13990</th>\n",
       "      <td>film</td>\n",
       "      <td>33543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28037</th>\n",
       "      <td>one</td>\n",
       "      <td>19432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22751</th>\n",
       "      <td>like</td>\n",
       "      <td>16009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39435</th>\n",
       "      <td>time</td>\n",
       "      <td>11280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "26222  movi  36240\n",
       "13990  film  33543\n",
       "28037   one  19432\n",
       "22751  like  16009\n",
       "39435  time  11280"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_count.items(), columns = [\"word\", \"count\"]).sort_values(by=\"count\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pytorch_dir): # Make sure that the folder exists\n",
    "    os.makedirs(pytorch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pytorch_dir, 'word_dict_enhanced.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_and_pad(word_dict, sentence, pad=500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in tqdm(data,leave=True):\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [00:00<00:00, 30426.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tf_X, train_X_tf_len = convert_and_pad_data(word_dict, train_pp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 28654.93it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tf_X, test_X_tf_len = convert_and_pad_data(word_dict, test_pp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [00:00<00:00, 32224.15it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_tf_X, valid_X_tf_len = convert_and_pad_data(word_dict, valid_pp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_tf_len), pd.DataFrame(train_tf_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(pytorch_dir, 'train.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([pd.DataFrame(valid_y), pd.DataFrame(valid_X_tf_len), pd.DataFrame(valid_tf_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(pytorch_dir, 'valid.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name aadelmo to get Role path.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.session.Session(region_name=\"us-east-1\"))\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/sentiment_rnn'\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except Exception as err:\n",
    "    role = \"arn:aws:iam::977053370764:role/service-role/AmazonSageMaker-ExecutionRole-20201202T141643\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-977053370764/sagemaker/sentiment_rnn'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = sagemaker_session.upload_data(path=pytorch_dir, bucket=bucket, key_prefix=prefix)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(pytorch_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "valid_sample = pd.read_csv(os.path.join(pytorch_dir, 'valid.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "valid_sample_y = torch.from_numpy(valid_sample[[0]].values).float().squeeze()\n",
    "valid_sample_X = torch.from_numpy(valid_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "valid_sample_ds = torch.utils.data.TensorDataset(valid_sample_X, valid_sample_y)\n",
    "\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)\n",
    "valid_sample_dl = torch.utils.data.DataLoader(valid_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "def train(model, train_loader, valid_loader, epochs, optimizer, loss_fn, device):\n",
    "    report_train = pd.DataFrame(columns=[\"epoch\", \"trainError\", \"validError\"])\n",
    "    best_valid_BCELoss = 9999999999\n",
    "    BCELoss_list = []\n",
    "    valid_BCELoss_list = []\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_valid_loss = 0        \n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = loss_fn(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()            \n",
    "            total_loss += loss.data.item()\n",
    "        for block in valid_loader:     \n",
    "            block_X, block_y = block\n",
    "            \n",
    "            block_X = block_X.to(device)\n",
    "            block_y = block_y.to(device)\n",
    "            output_valid = model(block_X)\n",
    "            valid_loss = loss_fn(output_valid, block_y)\n",
    "            total_valid_loss += valid_loss.data.item()\n",
    "        BCELoss = total_loss/len(train_loader)\n",
    "        BCELoss_list.append(BCELoss)\n",
    "        valid_BCELoss = total_valid_loss/len(valid_loader)\n",
    "        valid_BCELoss_list.append(valid_BCELoss)\n",
    "        if valid_BCELoss < best_valid_BCELoss: \n",
    "            dummy_input = torch.tensor(block_X).to(device).long()\n",
    "            torch.onnx.export(model, dummy_input, f\"models/best_model.onnx\")\n",
    "            best_valid_BCELoss = BCELoss\n",
    "        \n",
    "        desc = (f'Epoch: {epoch}, train_loss: {BCELoss}, valid_loss: {valid_BCELoss}')\n",
    "        print(desc)\n",
    "        to_append = [epoch, BCELoss, valid_BCELoss]\n",
    "        report_train_length = len(report_train)\n",
    "        report_train.loc[report_train_length] = to_append\n",
    "        #print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "        display.clear_output(wait=True)\n",
    "        if epoch == 1:\n",
    "            pl.plot(BCELoss_list, '-b', label=\"TrainError\")\n",
    "            pl.plot(valid_BCELoss_list, '-r', label=\"ValidationError\")\n",
    "            pl.legend(loc='upper right')\n",
    "        else:\n",
    "            pl.plot(BCELoss_list, '-b')\n",
    "            pl.plot(valid_BCELoss_list, '-r')\n",
    "        pl.xlim(1, epochs)\n",
    "        pl.ylim(0, 2)\n",
    "        display.display(pl.gcf())\n",
    "        time.sleep(1.0)\n",
    "    return report_train, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.49s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(64, 30, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "report_train, trained_model = train(model, train_sample_dl, valid_sample_dl, 5, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"enhanced\",\n",
    "                    py_version=\"py3\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.p2.xlarge',\n",
    "#                   hyperparameters={\n",
    "#                     'objective''binary:logistic'\n",
    "# #                         'epochs': 10,\n",
    "# #                         'hidden_dim': 200,\n",
    "#                     }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = estimator, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:loss',\n",
    "                                               metric_definitions = [{'Name': 'validation:loss',\n",
    "                       'Regex': 'loss (\\S+)'}],# The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 2, # The total number of models to train\n",
    "                                               max_parallel_jobs = 1, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'epochs': IntegerParameter(3, 10),\n",
    "                                                    'hidden_dim': IntegerParameter(50, 200),\n",
    "                                                    'embedding_dim': IntegerParameter(32, 64)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_sample = len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(n_test_sample)):\n",
    "    pr_data_X = test_tf_X[idx]\n",
    "    pr_data_len = test_X_tf_len[idx]\n",
    "    pr_data_pack = np.hstack((pr_data_len, pr_data_X))\n",
    "    pr_data_pack = pr_data_pack.reshape(1, -1)\n",
    "    pr_data = torch.from_numpy(pr_data_pack)\n",
    "    pr_data = pr_data.to(device)\n",
    "    model.eval()\n",
    "    result = model(pr_data).detach().numpy()\n",
    "    predicted_values.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "roc_auc = roc_auc_score(test_y[:n_test_sample], predicted_values)\n",
    "fpr, tpr, _ = roc_curve(test_y[:n_test_sample], predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y[:n_test_sample], np.rint(predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y[:n_test_sample], np.rint(predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
